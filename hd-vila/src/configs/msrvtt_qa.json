{
    "train_datasets": [
      {
        "name": "msrvtt_qa",
        "txt": {
          "msrvtt_qa": "data/msrvtt_qa/train.jsonl"
        },
        "vis": "data/msrvtt_retrieval/videos_6fps"
      }
    ],
    "val_datasets": [
      {
        "name": "msrvtt_qa",
        "txt": {
          "msrvtt_qa": "data/msrvtt_qa/val.jsonl"
        },
        "vis": "data/msrvtt_retrieval/videos_6fps"
      }
    ],
    "ans2label_path": "data/msrvtt_qa/train_ans2label.json",
    "max_txt_len": 100,
    "max_img_size": 448,
    "fps": 2,
    "reshape_size": [180, 288],
    "crop_size": [160, 256],
    "sample_rate": 4,
    "num_frm": 7,
    "train_n_clips": 1,
    "score_agg_func": "lse",
    "max_n_example_per_group": 1,
    "model_config": "src/configs/base_model_large.json",
    "e2e_weights_path": "data/pretrained/hdvila_stage2.pt",
    "mmdetection_weights_path": "data/pretrained/res50_mmdetection.pth",
    "bert_weights_path": "data/pretrained/bert-large-uncased/pytorch_model.bin",
    "tokenizer_dir": "data/pretrained/bert-base-uncased/",
    "output_dir": "data/output/videoqa/msrvtt_qa",
    "train_batch_size": 16,
    "val_batch_size": 16,
    "gradient_accumulation_steps": 4,
    "num_train_epochs": 20,
    "min_valid_steps": 1,
    "num_valid": 20,
    "save_steps_ratio": 0.2,
    "learning_rate": 1e-5,
    "weight_decay": 0.3,
    "decay": "linear",
    "optim": "adamw",
    "betas": [0.9, 0.98],
    "dropout": 0.3,
    "grad_norm": 5.0,
    "cnn_learning_rate": 1e-5,
    "cnn_weight_decay": 0.3,
    "cnn_lr_decay": "linear",
    "align_learning_rate": 1e-5,
    "align_weight_decay": 0.3,
    "seed":66,
    "fp16": 1,
    "classifier": "mlp",
    "cls_hidden_scale": 2,
    "task": "msrvtt_qa",
  
    "resnet_depth": 50,
    "resnet_frozen_stage": -1,
    "timesformer_depth": 4,
    "timesformer_heads": 16,
    "backbone_channels": [256, 512, 1024, 2048],
    "backbone_downsample": [4, 8, 16, 32],
    "backbone_channel_in_size": 2048,
    "hidden_size": 1024,
  
    "inference_model_step": 0,
    "inference_txt_db": "data/txt_db/msrvtt_qa/test.jsonl",
    "inference_img_db": "data/vis_db/msrvtt_video_clips/videos_6fps",
    "inference_batch_size": 4,
    "inference_n_clips": 8
  }